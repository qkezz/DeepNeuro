# -*- coding: utf-8 -*-
"""DL_lab9.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mrkgQCihyddr6uiq_KsOEctnfnJOvATm
"""

!pip install accelerate transformers
!pip install --upgrade langchain langchain-huggingface langchain-community
!pip install langgraph
!pip install wikipedia
!pip install -U langchain langchain-community

from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
from langchain_huggingface import HuggingFacePipeline
from langchain_core.tools import Tool
from langchain_core.prompts import PromptTemplate
from langgraph.prebuilt import create_react_agent
from datetime import datetime
import torch

model_id = "Qwen/Qwen3-4B"
tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(
    model_id,
    device_map="auto",
    dtype=torch.float16,
)

def segodnya():
    curdata = datetime.now()
    days = ["понедельник", "вторник", "среда", "четверг", "пятница", "суббота", "воскресенье"]
    months = ["января", "февраля", "марта", "апреля", "мая", "июня",
              "июля", "августа", "сентября", "октября", "ноября", "декабря"]
    return f"{curdata.day} {months[curdata.month-1]} {curdata.year} года, {curdata.hour:02d}:{curdata.minute:02d}:{curdata.second:02d} ({days[curdata.weekday()]})"

date_tool = Tool(
    name="Получить_текущую_дату",
    func=segodnya,
    description="""Используй для вопросов о дате, времени, дне недели."""
)

hf_pipeline = pipeline(
    "text-generation",
    model=model,
    tokenizer=tokenizer,
    max_new_tokens=200,
    temperature=0.1,
    device_map="auto"
)

llm = HuggingFacePipeline(pipeline=hf_pipeline)

agent_prompt = PromptTemplate.from_template("""
Ты — помощник с доступом к инструментам.
Инструменты:
{tools}
Если вопрос о дате или времени — используй инструмент "Получить_текущую_дату".
Иначе отвечай сам.
Вопрос: {input}
""")

agent = create_react_agent(
    model=model,
    tools=[date_tool],
    prompt=agent_prompt
)

from langgraph.graph import StateGraph, END
from typing import TypedDict, Annotated, List
import operator

class AgentState(TypedDict):
    messages: Annotated[List[str], operator.add]
    next: str

graph = StateGraph(AgentState)

def call_agent(state: AgentState):
    input_text = state.get("messages", [""])[-1] if state.get("messages") else ""

    if any(word in input_text.lower() for word in ["дата", "время", "день", "час"]):
        from datetime import datetime
        curdata = datetime.now()
        response = f"Сегодня {curdata.day}.{curdata.month}.{curdata.year}, {curdata.hour}:{curdata.minute}"
    else:
        inputs = tokenizer(input_text, return_tensors="pt").to(model.device)
        outputs = model.generate(**inputs, max_new_tokens=50)
        response = tokenizer.decode(outputs[0], skip_special_tokens=True)

    return {"messages": [response], "next": "end"}

graph.add_node("agent", call_agent)
graph.set_entry_point("agent")
graph.add_edge("agent", END)
app = graph.compile()

test_queries = [
    "Какая сегодня дата?",
    "Сколько сейчас времени?",
    "Какой сегодня день недели?",
    "Что такое Python?"
]

results = []
for query in test_queries:
    print(f"Вопрос: {query}")
    result = app.invoke({"messages": [query], "next": "agent"})

    if "messages" in result:
        response = result["messages"][-1] if result["messages"] else "Нет ответа"
    else:
        response = str(result)

    print(f"Ответ: {response[:100]}..." if len(response) > 100 else f"Ответ: {response}")

    results.append((query, response))

with open('prompt.txt', 'w', encoding='utf-8') as f:
    f.write(agent_prompt.template)

with open('res.txt', 'w', encoding='utf-8') as f:
    f.write("Тестирование агента с инструментом даты\n\n")
    for query, response in results:
        f.write(f"Вопрос: {query}\n")
        f.write(f"Ответ: {response}\n")